{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621168\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.009957\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.013652\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.007556\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.042397\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.017380\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000560\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.011917\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.032508\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000434\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "Size (MB): 44.759905\n",
      "\n",
      "Test set: Average loss: 0.0329, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Elapsed time = 17.4654 milliseconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.11262033879756927, zero_point=61, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09514768421649933, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09894664585590363, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12858636677265167, zero_point=40)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10504203289747238, zero_point=65, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10541452467441559, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15124870836734772, zero_point=42)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.11462134122848511, zero_point=64, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10089487582445145, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.12451858818531036, zero_point=64)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.15685124695301056, zero_point=62)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10403899848461151, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10564051568508148, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15269815921783447, zero_point=42)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.10177133977413177, zero_point=66, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08121456205844879, zero_point=59, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.12062752991914749, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.13417695462703705, zero_point=63)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09224500507116318, zero_point=60, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08578155189752579, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.121030293405056, zero_point=42)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08898907899856567, zero_point=60, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08784744143486023, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08269806206226349, zero_point=60)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.13889659941196442, zero_point=68)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08361915498971939, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08268540352582932, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1264924257993698, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.23026679456233978, zero_point=34, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "Size (MB): 11.201811\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9906/10000 (99%)\n",
      "\n",
      "Elapsed time = 4.0257 milliseconds\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
