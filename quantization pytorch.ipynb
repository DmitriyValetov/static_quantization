{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621168\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.015462\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.048742\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.005975\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.084379\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.004594\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.007416\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.006230\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.004843\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.019515\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.759605\n",
      "\n",
      "Test set: Average loss: 0.0305, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Elapsed time = 13.4575 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.1162254735827446, zero_point=60, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10319922119379044, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10608040541410446, zero_point=68, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15046177804470062, zero_point=48)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.11313275992870331, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10492662340402603, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1681116670370102, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.10604237020015717, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10008783638477325, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.1166030615568161, zero_point=61)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.17182154953479767, zero_point=59)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10056886821985245, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10080251842737198, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.15597230195999146, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.09873053431510925, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08331657946109772, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.11426330357789993, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.14108414947986603, zero_point=62)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08815984427928925, zero_point=59, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08516261726617813, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.13439910113811493, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.08295468986034393, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08274055272340775, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08589211851358414, zero_point=62)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.13412587344646454, zero_point=60)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08254192769527435, zero_point=58, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08536262065172195, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.12848719954490662, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.21647149324417114, zero_point=34, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.201611\n",
      "\n",
      "Test set: Average loss: 0.0312, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Elapsed time = 3.6907 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
