{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-training static quantization (Pytorch) - ResNet18\n",
    "In this notebook, you will be able to see how quantization in PyTorch can result in significant decreases in model size while increasing speed. Note that quantization is currently only supported for CPUs, so we will be utilizing GPUs / CUDA only for training and CPU for testing.\n",
    "Furthermore, while using complex dataset the accuracy might decrease upon quantization. By using a quantization configuration\n",
    "\n",
    "    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "we can significantly improve on the accuracy. We repeat the same exercise with the recommended configuration for quantizing for x86 architectures. This configuration does the following:\n",
    "1. Quantizes weights on a per-channel basis\n",
    "2. Uses a histogram observer that collects a histogram of activations and then picks quantization parameters in an optimal manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and visualize MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torchvision.datasets.MNIST('../data', train=True, download=True,\n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "               batch_size=64, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(torchvision.datasets.MNIST('../data', train=False, \n",
    "                                                    transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                                                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                    ])),\n",
    "              batch_size=64, shuffle=True, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 20\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18 model\n",
    "This code is taken from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py \n",
    "\n",
    "> NOTE: Training uses resnet model as is with addition operation and floating point inputs / outputs.      \n",
    "But when model is quantized while testing addition operation is replaced with FloatFunction and the inputs         / outputs are quantized/dequantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        groups: Number of blocked connections from input channels to output channels. Default: 1\n",
    "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=3, with specified out_planes\n",
    "    \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\n",
    "    \n",
    "    Args:\n",
    "        in_planes: number of channels in input image\n",
    "        out_planes: number of channels produced by convolution\n",
    "        stride: stride of the convolution. Default: 1\n",
    "        \n",
    "    Returns:\n",
    "        Convoluted layer of kernel size=1, with specified out_planes\n",
    "        \n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, quantize=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        # FloatFunction()\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Notice the addition operation in both scenarios\n",
    "        if self.quantize:\n",
    "            out = self.skip_add.add(out, identity)\n",
    "        else:\n",
    "            out += identity\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block=BasicBlock, layers=[2, 2, 2, 2], num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, mnist=False, quantize=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.quantize = quantize\n",
    "        if mnist:\n",
    "            num_channels = 1\n",
    "        else:\n",
    "            num_channels = 3\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace \n",
    "            # the 2x2 stride with a dilated convolution instead.\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(num_channels, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer, quantize=self.quantize))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, quantize=self.quantize))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # Input are quantized\n",
    "        if self.quantize:\n",
    "            x = self.quant(x)\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Outputs are dequantized\n",
    "        if self.quantize:\n",
    "            x = self.dequant(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "         # See note [TorchScript super()]\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\" Train the model with given dataset\n",
    "    \n",
    "    Args:\n",
    "        args: args like log interval\n",
    "        model: ResNet model to train\n",
    "        device: CPU/GPU\n",
    "        train_loader: dataset iterator\n",
    "        optimizer: optimizer to update weights\n",
    "        epoch: number of epochs to train for\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=-1), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.621168\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.013111\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.019656\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.003541\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.054527\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.003631\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.002661\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.006260\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.001697\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000963\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    " \n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    seed = 1\n",
    "    log_interval = 500\n",
    "    save_model = True\n",
    "    no_cuda = False\n",
    "    \n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(seed)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model = ResNet(num_classes=10, mnist=True).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    args = {}\n",
    "    args[\"log_interval\"] = log_interval\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, quantize=False, fbgemm=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        modules_to_fuse = [['conv1', 'bn1'],\n",
    "                   ['layer1.0.conv1', 'layer1.0.bn1'],\n",
    "                   ['layer1.0.conv2', 'layer1.0.bn2'],\n",
    "                   ['layer1.1.conv1', 'layer1.1.bn1'],\n",
    "                   ['layer1.1.conv2', 'layer1.1.bn2'],\n",
    "                   ['layer2.0.conv1', 'layer2.0.bn1'],\n",
    "                   ['layer2.0.conv2', 'layer2.0.bn2'],\n",
    "                   ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
    "                   ['layer2.1.conv1', 'layer2.1.bn1'],\n",
    "                   ['layer2.1.conv2', 'layer2.1.bn2'],\n",
    "                   ['layer3.0.conv1', 'layer3.0.bn1'],\n",
    "                   ['layer3.0.conv2', 'layer3.0.bn2'],\n",
    "                   ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
    "                   ['layer3.1.conv1', 'layer3.1.bn1'],\n",
    "                   ['layer3.1.conv2', 'layer3.1.bn2'],\n",
    "                   ['layer4.0.conv1', 'layer4.0.bn1'],\n",
    "                   ['layer4.0.conv2', 'layer4.0.bn2'],\n",
    "                   ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
    "                   ['layer4.1.conv1', 'layer4.1.bn1'],\n",
    "                   ['layer4.1.conv2', 'layer4.1.bn2']]\n",
    "        model = torch.quantization.fuse_modules(model, modules_to_fuse)\n",
    "        if fbgemm:\n",
    "            model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        else:\n",
    "            model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model(data)\n",
    "        torch.quantization.convert(model, inplace=True)\n",
    "\n",
    "    print(model)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            st = time.time()\n",
    "            output = model(data)\n",
    "            et = time.time()\n",
    "            test_loss += F.nll_loss(F.log_softmax(output, dim=-1), target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance - unquantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (skip_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 44.759647\n",
      "\n",
      "Test set: Average loss: 0.0319, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Elapsed time = 16.2978 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.11714627593755722, zero_point=59, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09677639603614807, zero_point=65, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09692014008760452, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.13622069358825684, zero_point=44)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10218723118305206, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.11047836393117905, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.16740766167640686, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.1051705926656723, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10654043406248093, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.1264508217573166, zero_point=61)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.18151064217090607, zero_point=63)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.09983013570308685, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1074952781200409, zero_point=67, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1630573570728302, zero_point=38)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.11049623042345047, zero_point=56, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.08278947323560715, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.1226247027516365, zero_point=71)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.14110606908798218, zero_point=63)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0808715969324112, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.09146862477064133, zero_point=59, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1243346780538559, zero_point=39)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.09631902724504471, zero_point=68, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08376236259937286, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.08144966512918472, zero_point=60)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.12736359238624573, zero_point=60)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08210603147745132, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.08402752131223679, zero_point=60, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.1234922930598259, zero_point=41)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.22497941553592682, zero_point=33, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.201623\n",
      "\n",
      "Test set: Average loss: 0.0325, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Elapsed time = 3.8104 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): QuantizedConv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.08760909736156464, zero_point=59, padding=(3, 3))\n",
      "  (bn1): Identity()\n",
      "  (relu): QuantizedReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06844664365053177, zero_point=60, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.06678871065378189, zero_point=65, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.09793549031019211, zero_point=40)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07156423479318619, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07132363319396973, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.11885228753089905, zero_point=38)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.07447172701358795, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.07001384347677231, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.08454639464616776, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.11830207705497742, zero_point=61)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.06813806295394897, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.0711163803935051, zero_point=64, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.11247358471155167, zero_point=41)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.06933090090751648, zero_point=61, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05919481813907623, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.07747848331928253, zero_point=64)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.10020511597394943, zero_point=61)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.057989634573459625, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.06168752536177635, zero_point=61, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.09109360724687576, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.06077266484498978, zero_point=63, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05918044596910477, zero_point=62, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.05820450559258461, zero_point=63)\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (skip_add): QFunctional(scale=0.09194763004779816, zero_point=61)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05817713961005211, zero_point=62, padding=(1, 1))\n",
      "      (bn1): Identity()\n",
      "      (relu): QuantizedReLU(inplace=True)\n",
      "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.05844741314649582, zero_point=63, padding=(1, 1))\n",
      "      (bn2): Identity()\n",
      "      (skip_add): QFunctional(scale=0.09478463977575302, zero_point=40)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): QuantizedLinear(in_features=512, out_features=10, scale=0.2095915526151657, zero_point=32, qscheme=torch.per_channel_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0255]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 11.28281\n",
      "\n",
      "Test set: Average loss: 0.0323, Accuracy: 9898/10000 (99%)\n",
      "\n",
      "Elapsed time = 3.7227 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "encoder = ResNet(num_classes=10, mnist=True, quantize=True)\n",
    "loaded_dict_enc = torch.load('mnist_cnn.pt', map_location=device)\n",
    "encoder.load_state_dict(loaded_dict_enc)\n",
    "test(model=encoder, device=device, test_loader=test_loader, quantize=True, fbgemm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
